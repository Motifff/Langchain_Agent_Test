{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9732067-71c7-46f7-ad09-381b3bf21a27",
   "metadata": {},
   "source": [
    "# Generative Agents in LangChain\n",
    "\n",
    "This notebook implements a generative agent based on the paper [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/abs/2304.03442) by Park, et. al.\n",
    "\n",
    "In it, we leverage a time-weighted Memory object backed by a LangChain Retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53f81c37-db45-4fdc-843c-aa8fd2a9e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8851c370-b395-4b80-a79d-486a38ffc244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81824e76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "USER_NAME = \"Pam\"  # The name you want to use when interviewing the agent.\n",
    "\n",
    "# Local LLM\n",
    "LLM = ChatOllama(\n",
    "    model=\"qwen2\",\n",
    "    keep_alive=-1, # keep the model loaded indefinitely\n",
    "    temperature=0,\n",
    "    max_new_tokens=4096 # officailly 4096\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da1649-d88f-4973-b655-7042975cde7e",
   "metadata": {},
   "source": [
    "### Generative Agent Memory Components\n",
    "\n",
    "This tutorial highlights the memory of generative agents and its impact on their behavior. The memory varies from standard LangChain Chat memory in two aspects:\n",
    "\n",
    "1. **Memory Formation**\n",
    "\n",
    "   Generative Agents have extended memories, stored in a single stream:\n",
    "      1. Observations - from dialogues or interactions with the virtual world, about self or others\n",
    "      2. Reflections - resurfaced and summarized core memories\n",
    "\n",
    "\n",
    "2. **Memory Recall**\n",
    "\n",
    "   Memories are retrieved using a weighted sum of salience, recency, and importance.\n",
    "\n",
    "You can review the definitions of the `GenerativeAgent` and `GenerativeAgentMemory` in the [reference documentation](\"https://api.python.langchain.com/en/latest/modules/experimental.html\") for the following imports, focusing on `add_memory` and `summarize_related_memories` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "043e5203-6a41-431c-9efa-3e1743d7d25a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.generative_agents import (\n",
    "    GenerativeAgent,\n",
    "    GenerativeAgentMemory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361bd49e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Memory Lifecycle\n",
    "\n",
    "Summarizing the key methods in the above: `add_memory` and `summarize_related_memories`.\n",
    "\n",
    "When an agent makes an observation, it stores the memory:\n",
    "    \n",
    "1. Language model scores the memory's importance (1 for mundane, 10 for poignant)\n",
    "2. Observation and importance are stored within a document by TimeWeightedVectorStoreRetriever, with a `last_accessed_time`.\n",
    "\n",
    "When an agent responds to an observation:\n",
    "\n",
    "1. Generates query(s) for retriever, which fetches documents based on salience, recency, and importance.\n",
    "2. Summarizes the retrieved information\n",
    "3. Updates the `last_accessed_time` for the used documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa3ca02",
   "metadata": {},
   "source": [
    "## Create a Generative Character\n",
    "\n",
    "\n",
    "\n",
    "Now that we've walked through the definition, we will create two characters named \"Tommie\" and \"Eve\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee9c1a1d-c311-4f1c-8131-75fccd9025b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import faiss\n",
    "\n",
    "\n",
    "def score_normalizer(val: float) -> float:\n",
    "    ret = 1.0 - 1.0 / (1.0 + np.exp(val))\n",
    "    #print(\"val: \"+str(float(val))+\"_\"+\"ret: \"+str(ret))\n",
    "    return ret\n",
    "\n",
    "def create_new_memory_retriever():\n",
    "    \"\"\"Create a new vector store retriever unique to the agent.\"\"\"\n",
    "    # Define your embedding model\n",
    "    embeddings_model = OllamaEmbeddings(model=\"qwen2\")\n",
    "\n",
    "    # Automatically determine the size of the embeddings\n",
    "    test_embedding = embeddings_model.embed_query(\"test query\")\n",
    "    embedding_size = len(test_embedding)\n",
    "    \n",
    "    # Initialize the vectorstore as empty\n",
    "    index = faiss.IndexFlatL2(embedding_size)\n",
    "    \n",
    "    # Initialize FAISS vector store\n",
    "    vectorstore = FAISS(\n",
    "        embeddings_model,\n",
    "        index,\n",
    "        InMemoryDocstore({}),\n",
    "        {},\n",
    "        relevance_score_fn=score_normalizer,\n",
    "        normalize_L2=True\n",
    "    )\n",
    "    \n",
    "    # Create and return the retriever\n",
    "    return TimeWeightedVectorStoreRetriever(\n",
    "        vectorstore=vectorstore, \n",
    "        other_score_keys=[\"importance\"], \n",
    "        k=15\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7884f9dd-c597-4c27-8c77-1402c71bc2f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tommies_memory = GenerativeAgentMemory(\n",
    "    llm=LLM,\n",
    "    memory_retriever=create_new_memory_retriever(),\n",
    "    verbose=False,\n",
    "    reflection_threshold=8,  # we will give this a relatively low number to show how reflection works\n",
    ")\n",
    "\n",
    "tommie = GenerativeAgent(\n",
    "    name=\"Tommie\",\n",
    "    age=25,\n",
    "    traits=\"anxious, likes design, talkative\",  # You can add more persistent traits here\n",
    "    status=\"looking for a job\",  # When connected to a virtual world, we can have the characters update their status\n",
    "    llm=LLM,\n",
    "    memory=tommies_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c524d529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Tommie (age: 25)\n",
      "Innate traits: anxious, likes design, talkative\n",
      "Tommie is characterized by being straightforward, honest, and dependable. He values integrity and reliability in his interactions and commitments.\n"
     ]
    }
   ],
   "source": [
    "# The current \"Summary\" of a character can't be made because the agent hasn't made\n",
    "# any observations yet.\n",
    "print(tommie.get_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4be60979-d56e-4abf-a636-b34ffa8b7fba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can add memories directly to the memory object\n",
    "tommie_observations = [\n",
    "    \"Tommie remembers his dog, Bruno, from when he was a kid\",\n",
    "    \"Tommie feels tired from driving so far\",\n",
    "    \"Tommie sees the new home\",\n",
    "    \"The new neighbors have a cat\",\n",
    "    \"The road is noisy at night\",\n",
    "    \"Tommie is hungry\",\n",
    "    \"Tommie tries to get some rest.\",\n",
    "]\n",
    "\n",
    "for observation in tommie_observations:\n",
    "    tommie.memory.add_memory(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6992b48b-697f-4973-9560-142ef85357d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Tommie (age: 25)\n",
      "Innate traits: anxious, likes design, talkative\n",
      "Tommie appears to be someone who has recently moved into a new home, likely after a long journey as he feels tired from driving far. He seems to have a nostalgic connection with dogs, possibly remembering his childhood pet, Bruno. Tommie values rest and might be sensitive to noise at night, as indicated by the mention of a noisy road. Additionally, he is experiencing hunger, suggesting that he may need to address his basic needs soon.\n"
     ]
    }
   ],
   "source": [
    "# Now that Tommie has 'memories', their self-summary is more descriptive, though still rudimentary.\n",
    "# We will see how this summary updates after more observations to create a more rich description.\n",
    "print(tommie.get_summary(force_refresh=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
